# Setting up

When compiling sample programs to LLVM IR, I realized that clang was generating code that used `alloca, load, store` opposed to `phi` instructions. With a little help on Zulip, Professor Sampson reccomended to run the `mem2reg` pass which according to the [LLVM Docs](https://llvm.org/docs/Passes.html#mem2reg-promote-memory-to-register)
```
Promotes memory references to be register references. It promotes alloca instructions which only have loads and stores as uses. An alloca is transformed by using dominator frontiers to place phi nodes, then traversing the function in depth-first order to rewrite loads and stores as appropriate. This is just the standard SSA construction algorithm to construct “pruned” SSA form
```

I used `clang` and `opt` to manually verify it was working as expected:
```
clang -S -emit-llvm -Xclang -disable-O0-optnone a.c  
opt -mem2reg -S a.ll
```

Note the disable-O0-optnone option. `clang`` started to add optnone attribute to each function, which prevents further optimizations afterwards including mem2reg pass. To prevent that, add -Xclang -disable-O0-optnone to clang [source](https://stackoverflow.com/questions/46513801/llvm-opt-mem2reg-has-no-effect)

Now we are ready to write our pass.

# Setting up the pass

I created a `LoopPass` to do this work.

The first interesting thing we needed to do was to run `mem2reg` before performing the pass. We do this in the code instead of by the command line so someone wanting to use this pass in the future does not have to incur the complexity of setting the options on the command line:

```
static void registerLICMPass(const PassManagerBuilder &, legacy::PassManagerBase &PM) {
   PM.add(createPromoteMemoryToRegisterPass());
   PM.add(new LICMPass());
 }
```

The `createPromoteMemoryToRegisterPass` function does this for us. I will admit, it was a little tough to find this function when searching for `mem2reg` in the docs. I had to refer to the source code directly which is fine, but obviously less than ideal. Finding which header file to import also was harder than it should have been (you cant import the `Mem2Reg.h` file, we must import the `Utils.h` header instead).

At this point we can use `clang` with our `LICMPass` which will output the pruned SSA Code. Now its time to actualy implement `runOnLoop`.

In `runOnLoop` we hoist variables in the loop to the header that are invariant with a call to `makeLoopInvariant`. We run this until convergence.

`makeLoopInvariant` iterates over all blocks in the loop, and over all instructions in a given block. For each instruction we call the `makeLoopInvariant` function belonging to the loop. If we changed any item in any of the blocks we return `true`. However if we hoist an instruction out of a block, we stop iterating over the instructions over that block since modifying a list of instructions while iterating over it can cause unwanted behavior. Since we know that `changed` was set to true, that means we will make another call to `makeLoopInvarient` from `runOnLoop`, we know that we will iterate over that block to see if it has any more loop invariant instructions that we can hoist. Taking this approach allows us to keep the code clean and simple.

# Testing
 
To test, I took benches from the [embench-iot benchmars](https://github.com/embench/embench-iot/blob/master/src/tarfind/tarfind.c)

Specifically I used libwikisort.c, md5.c, mont64.cd, nettle-sha256.c, and tarfind.c.

For each of these benchmarks I calculated the time it took with no optimization, the time it took with optimization. The results are summarized by the following table:

Benchmark      |   Base |   LICM | 
---------      |  ----- |  ----- | 
aha-mont64     |   3.25 |   3.21 | 
crc32          |   2.41 |   2.41 |    
cubic          |  79.64 |  75.84 |
edn            |   4.78 |   4.76 |
huffbench      |   5.69 |   5.73 |
matmult-int    |  10.87 |  10.81 |
minver         |  30.82 |  30.72 |
nbody          | 236.36 | 237.72 |
nettle-aes     |   5.35 |   5.32 |
nettle-sha256  |   4.17 |   4.14 |
nsichneu       |   5.94 |   5.89 |
picojpeg       |   7.03 |   6.99 |
primecount     |   2.27 |   2.25 |
qrduino        |   2.33 |   2.17 |
sglib-combined |   4.29 |   4.06 |
slre           |   4.68 |   4.63 |
st             |  89.67 |  90.15 |
statemate      |   9.26 |   9.24 |
tarfind        |   9.38 |   9.13 |
ud             |   4.49 |   4.59 |
wikisort       |  31.44 |  30.44 |

You can see that for some programs we saw a speedup and for some we saw a slight slow down.

# Summary

Overall, I enjoyed working in LLVM. The existing architecture made my life much easier. I do wish the documentation for LLVM was better! Next steps with this implementation would be to assert the same functionality between Base and LICM benchmarks. I was not sure how to do this so I wrote some sample programs to assert by hand.
